{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyBs+IXfkZhXPt89g0T1sP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeleOeO/Artificial-Intelligence-Projects/blob/main/Sarcasm_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTyu2MabRa1L"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/learning-datasets/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPR6Q0A--nGj",
        "outputId": "e02ca106-def9-4974-fcdc-265860d2e955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-29 10:04:13--  https://storage.googleapis.com/learning-datasets/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 2607:f8b0:4023:c0b::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-03-29 10:04:13 (165 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000"
      ],
      "metadata": {
        "id": "tZ8bQSAuI3XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/tmp/sarcasm.json\", \"r\")\n",
        "datastore = json.load(f)\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "\n",
        "for item in datastore:\n",
        "  sentences.append(item[\"headline\"])\n",
        "  labels.append(item[\"is_sarcastic\"])\n",
        "  urls.append(item[\"article_link\"])\n",
        "\n",
        "print(sentences[:10])"
      ],
      "metadata": {
        "id": "2s6Yku3BS78a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfc81ad-1e47-4f97-c129-113746fe652b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"former versace store clerk sues over secret 'black code' for minority shoppers\", \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", \"mom starting to fear son's web series closest thing she will have to grandchild\", 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas', 'j.k. rowling wishes snape happy birthday in the most magical way', \"advancing the world's women\", 'the fascinating case for eating lab-grown meat', 'this ceo will send your kids to school, if you work for his company', 'top snake handler leaves sinking huckabee campaign', \"friday's morning email: inside trump's presser for the ages\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(oov_token = oov_tok, num_words=vocab_size)\n",
        "\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences, padding = \"post\")"
      ],
      "metadata": {
        "id": "-X-g-zbe_D05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_index)\n",
        "print(padded[0])\n",
        "print(padded.shape)"
      ],
      "metadata": {
        "id": "juHDFKeEBg1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create training sentence and label and testing sentence and label\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "metadata": {
        "id": "3xWAmzzvEUFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index= tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding = padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding =padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "bPh7jJBEI1f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "training_sequences = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_sequences = np.array(testing_padded)\n",
        "testing_labels =np.array(testing_labels)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    keras.layers.GlobalAveragePooling1D(),\n",
        "    keras.layers.Dense(24, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dd_ef5ycK0l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_sequences, training_labels, epochs=30, validation_data=(testing_sequences, testing_labels), verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAoyuKx_otYt",
        "outputId": "e2908be8-22f9-4247-ca5d-7340046956d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "625/625 - 4s - loss: 0.6645 - accuracy: 0.5954 - val_loss: 0.5842 - val_accuracy: 0.7180 - 4s/epoch - 6ms/step\n",
            "Epoch 2/30\n",
            "625/625 - 3s - loss: 0.4396 - accuracy: 0.8306 - val_loss: 0.3880 - val_accuracy: 0.8426 - 3s/epoch - 5ms/step\n",
            "Epoch 3/30\n",
            "625/625 - 3s - loss: 0.3176 - accuracy: 0.8725 - val_loss: 0.3539 - val_accuracy: 0.8517 - 3s/epoch - 4ms/step\n",
            "Epoch 4/30\n",
            "625/625 - 4s - loss: 0.2629 - accuracy: 0.8975 - val_loss: 0.3411 - val_accuracy: 0.8568 - 4s/epoch - 6ms/step\n",
            "Epoch 5/30\n",
            "625/625 - 3s - loss: 0.2276 - accuracy: 0.9119 - val_loss: 0.3402 - val_accuracy: 0.8591 - 3s/epoch - 4ms/step\n",
            "Epoch 6/30\n",
            "625/625 - 3s - loss: 0.2003 - accuracy: 0.9232 - val_loss: 0.3628 - val_accuracy: 0.8462 - 3s/epoch - 4ms/step\n",
            "Epoch 7/30\n",
            "625/625 - 3s - loss: 0.1783 - accuracy: 0.9331 - val_loss: 0.3622 - val_accuracy: 0.8553 - 3s/epoch - 4ms/step\n",
            "Epoch 8/30\n",
            "625/625 - 3s - loss: 0.1600 - accuracy: 0.9413 - val_loss: 0.3683 - val_accuracy: 0.8559 - 3s/epoch - 5ms/step\n",
            "Epoch 9/30\n",
            "625/625 - 3s - loss: 0.1454 - accuracy: 0.9474 - val_loss: 0.3848 - val_accuracy: 0.8544 - 3s/epoch - 6ms/step\n",
            "Epoch 10/30\n",
            "625/625 - 3s - loss: 0.1303 - accuracy: 0.9559 - val_loss: 0.4056 - val_accuracy: 0.8508 - 3s/epoch - 4ms/step\n",
            "Epoch 11/30\n",
            "625/625 - 3s - loss: 0.1185 - accuracy: 0.9596 - val_loss: 0.4231 - val_accuracy: 0.8515 - 3s/epoch - 5ms/step\n",
            "Epoch 12/30\n",
            "625/625 - 3s - loss: 0.1092 - accuracy: 0.9618 - val_loss: 0.4471 - val_accuracy: 0.8463 - 3s/epoch - 4ms/step\n",
            "Epoch 13/30\n",
            "625/625 - 4s - loss: 0.0997 - accuracy: 0.9668 - val_loss: 0.4772 - val_accuracy: 0.8395 - 4s/epoch - 6ms/step\n",
            "Epoch 14/30\n",
            "625/625 - 3s - loss: 0.0929 - accuracy: 0.9681 - val_loss: 0.5008 - val_accuracy: 0.8432 - 3s/epoch - 4ms/step\n",
            "Epoch 15/30\n",
            "625/625 - 2s - loss: 0.0845 - accuracy: 0.9719 - val_loss: 0.5293 - val_accuracy: 0.8417 - 2s/epoch - 4ms/step\n",
            "Epoch 16/30\n",
            "625/625 - 3s - loss: 0.0786 - accuracy: 0.9733 - val_loss: 0.5504 - val_accuracy: 0.8369 - 3s/epoch - 4ms/step\n",
            "Epoch 17/30\n",
            "625/625 - 4s - loss: 0.0716 - accuracy: 0.9774 - val_loss: 0.5796 - val_accuracy: 0.8354 - 4s/epoch - 6ms/step\n",
            "Epoch 18/30\n",
            "625/625 - 2s - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.6113 - val_accuracy: 0.8356 - 2s/epoch - 4ms/step\n",
            "Epoch 19/30\n",
            "625/625 - 3s - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.6450 - val_accuracy: 0.8326 - 3s/epoch - 4ms/step\n",
            "Epoch 20/30\n",
            "625/625 - 3s - loss: 0.0580 - accuracy: 0.9819 - val_loss: 0.8154 - val_accuracy: 0.8158 - 3s/epoch - 4ms/step\n",
            "Epoch 21/30\n",
            "625/625 - 3s - loss: 0.0523 - accuracy: 0.9840 - val_loss: 0.7077 - val_accuracy: 0.8275 - 3s/epoch - 5ms/step\n",
            "Epoch 22/30\n",
            "625/625 - 3s - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.7542 - val_accuracy: 0.8262 - 3s/epoch - 5ms/step\n",
            "Epoch 23/30\n",
            "625/625 - 3s - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.7954 - val_accuracy: 0.8246 - 3s/epoch - 5ms/step\n",
            "Epoch 24/30\n",
            "625/625 - 3s - loss: 0.0422 - accuracy: 0.9872 - val_loss: 0.8281 - val_accuracy: 0.8213 - 3s/epoch - 4ms/step\n",
            "Epoch 25/30\n",
            "625/625 - 4s - loss: 0.0384 - accuracy: 0.9891 - val_loss: 0.9089 - val_accuracy: 0.8211 - 4s/epoch - 6ms/step\n",
            "Epoch 26/30\n",
            "625/625 - 3s - loss: 0.0368 - accuracy: 0.9880 - val_loss: 0.8865 - val_accuracy: 0.8141 - 3s/epoch - 4ms/step\n",
            "Epoch 27/30\n",
            "625/625 - 2s - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.9498 - val_accuracy: 0.8192 - 2s/epoch - 4ms/step\n",
            "Epoch 28/30\n",
            "625/625 - 2s - loss: 0.0322 - accuracy: 0.9901 - val_loss: 0.9899 - val_accuracy: 0.8193 - 2s/epoch - 4ms/step\n",
            "Epoch 29/30\n",
            "625/625 - 3s - loss: 0.0280 - accuracy: 0.9919 - val_loss: 1.0027 - val_accuracy: 0.8113 - 3s/epoch - 4ms/step\n",
            "Epoch 30/30\n",
            "625/625 - 4s - loss: 0.0265 - accuracy: 0.9926 - val_loss: 1.0623 - val_accuracy: 0.8144 - 4s/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d6a079820>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [\n",
        "    \"God gave men both a penis and a brain, but unfortunately not enough blood supply to run both at the same time.\",\n",
        "    \"The sun is out today.\",\n",
        "    \"There's so much going on, it's almost like God is punishing us.\",\n",
        "    \"When people ask me stupid questions, it is my legal obligation to give a sarcastic remark.\",\n",
        "    \"Cows lose their jobs as milk prices drop\"\n",
        "]\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding = padding_type, truncating=trunc_type)\n",
        "\n",
        "for index,i in enumerate(model.predict(padded)):\n",
        "  if i >= 0.5:\n",
        "    print(\"'\"+ sentence[index]+\"'\"+ \": Sarcastic\")\n",
        "  else:\n",
        "    print(\"'\"+ sentence[index]+\"'\"+ \": Not sarcastic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PClWPYYttsVD",
        "outputId": "48d993ac-0049-4980-b1e1-b04e1d9ae700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "'God gave men both a penis and a brain, but unfortunately not enough blood supply to run both at the same time.': Sarcastic\n",
            "'The sun is out today.': Not sarcastic\n",
            "'There's so much going on, it's almost like God is punishing us.': Not sarcastic\n",
            "'When people ask me stupid questions, it is my legal obligation to give a sarcastic remark.': Not sarcastic\n",
            "'Cows lose their jobs as milk prices drop': Sarcastic\n"
          ]
        }
      ]
    }
  ]
}